{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a3d543d",
   "metadata": {},
   "source": [
    "<h1><center> Python project</center></h1>\n",
    "<h2><center>Current car prices and other relevant parameters from bazos.cz</center></h2>\n",
    "<h3><center>Daniel Brosko, Vojtěch Suchánek</center></h3>\n",
    "\n",
    "Our goal is to web-scrape advertisements listed on website bazos.cz, which is currently one of the most used websites for selling used cars in Czech republic. It has more than 15 000 car adds daily. On the other hand, it has really poor search options, which pretty much complicates searching for desired car based on your parameters.\n",
    "\n",
    "We are going to code algorithm, which will scan adds for the current day, pick those, which fulfill our conditions on date and car type and save their links. Then we will go to each link and save the text of the add. Then we will try to analyze the text of the add to find our parameters.\n",
    "\n",
    "This approach might also allow for longer time period analysis in further steps - we would collect data periodically and investigate the trends in price changes, number of ads for selected car added during particular days, and more. However, since this project should be designed as one-time run, we decided to limit the data to only current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d614ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed4447a",
   "metadata": {},
   "source": [
    "The commented line below displays the version of packages so they can be used in requirements.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c62140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94dc06",
   "metadata": {},
   "source": [
    "By the code in the following chunk, we checked that we are allowed to scrape particular parts of bazos.cz domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "988784bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bots = requests.get('https://auto.bazos.cz/robots.txt')\n",
    "#print(bots.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887d0ee",
   "metadata": {},
   "source": [
    "From the robots page we can see that our actions done in our projects are allowed, since we are not gonna use these search commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d424b1",
   "metadata": {},
   "source": [
    "In the next chunk, we import two .py scripts where we defined the functions search_model, and n_days_search to filter and include only advertisements relevant to our preferences. More comments on the functions are printed few chunks below - where we print the documentation, but also by looking at .py scripts directly in GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cc50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_search import search_model\n",
    "from n_days_search import n_days_search\n",
    "from data_mining import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4eb085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your desired car model here:\n",
      "octavia 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter your desired car model here:\")\n",
    "my_search = input()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6bc96",
   "metadata": {},
   "source": [
    "In the next chunk, we filter for the ads added today + max 5 days old. If we compared the number for today (2022-08-30) there were 98 at the time, while the number of all ads for the same car-model input was 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46497f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of past days (max. 5) that you want to include in your search here:\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter the number of past days (max. 5) that you want to include in your search here:\")\n",
    "my_days = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df339e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m soup_list \u001b[38;5;241m=\u001b[39m search_model(my_search)\n\u001b[1;32m      3\u001b[0m my_days \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(my_days)\n\u001b[0;32m----> 4\u001b[0m list_of_offers_url \u001b[38;5;241m=\u001b[39m \u001b[43mn_days_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_days\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoup_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/IES/Python/Python-project/n_days_search.py:44\u001b[0m, in \u001b[0;36mn_days_search\u001b[0;34m(n_days, soup_list)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# by the following code, we get the urls of each advertisement /offer/ (listed in the tabs we work with),\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# and save it to \"list_of_offers_url\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m list_of_offers_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m soup_list:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melement\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minzeraty inzeratyflex\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Now we specify on how many past days we want to include in our search\n",
    "soup_list = search_model(my_search)\n",
    "my_days = int(my_days)\n",
    "list_of_offers_url = n_days_search(my_days, soup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we print the documentation for our functions we imported earlier.\n",
    "\n",
    "help(search_model)\n",
    "\n",
    "help(n_days_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccd36f",
   "metadata": {},
   "source": [
    "Finally, we proceed to Data-mining part, where we extract the desired parameters - year of manufacture, year, and price. \n",
    "\n",
    "This is probably the most demanding part of the project - we need to extract the relevant data from unformated text. There is no official format of the text, so we tried to find a way how to extract this information from various formats. The results are not the best since sometimes it happen that our code is not able to recognize the unusual format of the parameter. In further steps, probably implementing some ML algorithm could improve the successful recognition significantly.\n",
    "\n",
    "We save all of those parameters along with the URLs of particular advertisements. We created a class ResultTable that has two methods - \"show_results\" and \"show_best\" by which we can display the best recommended ads for our desired car model.\n",
    "\n",
    "Hence, now we can take a look on potentially most interesting advertisements for us by following the URLs and checking the entire content of several ads instead of looking at \"thousands\" of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42795c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA/TEXT MINING PART\n",
    "result = get_info(list_of_offers_url)\n",
    "\n",
    "\n",
    "pd.options.display.max_colwidth = 120\n",
    "test = ResultTable(result)\n",
    "test.show_results(min_price = 50000, max_price = 350000, min_year = 2013, max_year = 2018, min_mileage = 100000, max_mileage = 200000)\n",
    "test.show_best(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bb1bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
